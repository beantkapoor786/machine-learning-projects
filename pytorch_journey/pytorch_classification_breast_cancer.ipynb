{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMKicHMimpt1+FySpVzzQPx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beantkapoor786/machine-learning-projects/blob/main/pytorch_journey/pytorch_classification_breast_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural network classification with PyTorch\n",
        "\n",
        "Classification is a problem of predicting whether something is one thing or another (there can be multiple things as the options)"
      ],
      "metadata": {
        "id": "tMxZ4qqOu6E9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# required packages\n",
        "from google.colab import files\n",
        "import io\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "ByEnn_UC1u9Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataset\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Mngon4fn523i",
        "outputId": "dfe024db-ba20-41b8-b71c-8576e4bb13cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d052dd9c-b7e7-47d7-88f3-d6e48df06b56\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d052dd9c-b7e7-47d7-88f3-d6e48df06b56\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving wdbc.data to wdbc.data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# every time I upload the same file, it changes the version number so gotta keep an eye on that\n",
        "df = pd.read_csv(io.BytesIO(uploaded['wdbc.data']), header = None)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "na4wIceS6cOu",
        "outputId": "d219a65f-142a-4090-a91f-a56ce3a4727f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0  1      2      3       4       5        6        7       8   \\\n",
              "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
              "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
              "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
              "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
              "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
              "\n",
              "        9   ...     22     23      24      25      26      27      28      29  \\\n",
              "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
              "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
              "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
              "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
              "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
              "\n",
              "       30       31  \n",
              "0  0.4601  0.11890  \n",
              "1  0.2750  0.08902  \n",
              "2  0.3613  0.08758  \n",
              "3  0.6638  0.17300  \n",
              "4  0.2364  0.07678  \n",
              "\n",
              "[5 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6a90c35-f015-47e8-850b-b6188a59217d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6a90c35-f015-47e8-850b-b6188a59217d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6a90c35-f015-47e8-850b-b6188a59217d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6a90c35-f015-47e8-850b-b6188a59217d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "Yu_zl7f571Hh",
        "outputId": "d9d83e33-e91f-4746-e095-a68291776dcc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0           2           3           4            5   \\\n",
              "count  5.690000e+02  569.000000  569.000000  569.000000   569.000000   \n",
              "mean   3.037183e+07   14.127292   19.289649   91.969033   654.889104   \n",
              "std    1.250206e+08    3.524049    4.301036   24.298981   351.914129   \n",
              "min    8.670000e+03    6.981000    9.710000   43.790000   143.500000   \n",
              "25%    8.692180e+05   11.700000   16.170000   75.170000   420.300000   \n",
              "50%    9.060240e+05   13.370000   18.840000   86.240000   551.100000   \n",
              "75%    8.813129e+06   15.780000   21.800000  104.100000   782.700000   \n",
              "max    9.113205e+08   28.110000   39.280000  188.500000  2501.000000   \n",
              "\n",
              "               6           7           8           9           10  ...  \\\n",
              "count  569.000000  569.000000  569.000000  569.000000  569.000000  ...   \n",
              "mean     0.096360    0.104341    0.088799    0.048919    0.181162  ...   \n",
              "std      0.014064    0.052813    0.079720    0.038803    0.027414  ...   \n",
              "min      0.052630    0.019380    0.000000    0.000000    0.106000  ...   \n",
              "25%      0.086370    0.064920    0.029560    0.020310    0.161900  ...   \n",
              "50%      0.095870    0.092630    0.061540    0.033500    0.179200  ...   \n",
              "75%      0.105300    0.130400    0.130700    0.074000    0.195700  ...   \n",
              "max      0.163400    0.345400    0.426800    0.201200    0.304000  ...   \n",
              "\n",
              "               22          23          24           25          26  \\\n",
              "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
              "mean    16.269190   25.677223  107.261213   880.583128    0.132369   \n",
              "std      4.833242    6.146258   33.602542   569.356993    0.022832   \n",
              "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
              "25%     13.010000   21.080000   84.110000   515.300000    0.116600   \n",
              "50%     14.970000   25.410000   97.660000   686.500000    0.131300   \n",
              "75%     18.790000   29.720000  125.400000  1084.000000    0.146000   \n",
              "max     36.040000   49.540000  251.200000  4254.000000    0.222600   \n",
              "\n",
              "               27          28          29          30          31  \n",
              "count  569.000000  569.000000  569.000000  569.000000  569.000000  \n",
              "mean     0.254265    0.272188    0.114606    0.290076    0.083946  \n",
              "std      0.157336    0.208624    0.065732    0.061867    0.018061  \n",
              "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
              "25%      0.147200    0.114500    0.064930    0.250400    0.071460  \n",
              "50%      0.211900    0.226700    0.099930    0.282200    0.080040  \n",
              "75%      0.339100    0.382900    0.161400    0.317900    0.092080  \n",
              "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
              "\n",
              "[8 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abc4afc5-8627-4e2f-b5c8-99f8862add2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>...</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>...</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>...</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>...</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>...</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>...</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>...</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abc4afc5-8627-4e2f-b5c8-99f8862add2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-abc4afc5-8627-4e2f-b5c8-99f8862add2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-abc4afc5-8627-4e2f-b5c8-99f8862add2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully imported our data. This data has 569 rows and 32 columns. Column 1 is ID so we can get rid of that. Column 2 is our label. M stands for malignant and B is benign. We'll have to separate these out from the dataframe. For desctription of training variables - https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic"
      ],
      "metadata": {
        "id": "3CFpEwLV6q9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split features and labels (also remove the ID column)\n",
        "X = df.drop(columns=df.columns[:2])\n",
        "y = df[1]\n",
        "# DO NOT RUN THIS CELL AGAIN, BE CAREFUL!"
      ],
      "metadata": {
        "id": "16rMbvUE8T2v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# before splitting data, we should scale our features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Before train/test split or after split on train only\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert to tensors\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "xERdWSK8V-lU"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# let's look at y_encoded, it's just an np array of 1 and 0, should be able to be converted to tensor\n",
        "y_encoded\n",
        "y_tensor = torch.tensor(y_encoded, dtype=torch.float32)\n",
        "# Hell yeah!"
      ],
      "metadata": {
        "id": "WoGwQXxH-FKS"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2p8BtCr_JKZ",
        "outputId": "9c43782c-4ab6-4fef-806d-1f1cb0627c50"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([569, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay awesome, we have our training data in `X_tensor` and labels in `y_tensor` - Malignant is 1 and Benign is 0. We are ready to roll. Let's split data into training and testing sets."
      ],
      "metadata": {
        "id": "PCzoYqBt_rKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# manual seed for pytorch\n",
        "torch.manual_seed(37)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-SjQ3l0DTIG",
        "outputId": "5a1b9398-16e9-4378-b9d9-7e91ecb276d0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ac243faa0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split data into traning and testing set (80% rows for training and 20% for test)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=37)"
      ],
      "metadata": {
        "id": "68zQIupsBbAR"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have split our tensors in training and test sets, we are ready to build our classification model."
      ],
      "metadata": {
        "id": "-GnPLKX8DMxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build model\n",
        "\n",
        "To do so, we want to -\n",
        "1. Setup device agnostic code so our code will run on an accelerator (GPU) if there is one available\n",
        "2. Construct a model (by subclassing `nn.Module`)\n",
        "3. Define a loss function and optimizer\n",
        "4. Create a training and test loop"
      ],
      "metadata": {
        "id": "8BeEW4j1C6j_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pytorch nn\n",
        "from torch import nn\n",
        "\n",
        "# make device agnosting code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Xqb9lXi1C7a0",
        "outputId": "1f37dd2d-07cc-4634-e996-36ae5d468534"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. construct a model that subclasses nn.Module\n",
        "class breast_cancer_model_v1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # 2. create 30 nn layers capable of handling our data - 30 columns\n",
        "    self.layer_1 = nn.Linear(in_features=30, out_features=100)\n",
        "    self.layer_2 = nn.Linear(in_features=100, out_features=50)\n",
        "    self.layer_3 = nn.Linear(in_features=50, out_features=25)\n",
        "    self.layer_4 = nn.Linear(in_features=25, out_features=10)\n",
        "    self.layer_5 = nn.Linear(in_features=10, out_features=5)\n",
        "    self.layer_6 = nn.Linear(in_features=5, out_features=3)\n",
        "    self.layer_7 = nn.Linear(in_features=3, out_features=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_7(self.layer_6(self.layer_5(self.layer_4(self.layer_3(self.layer_2(self.layer_1(x)))))))\n",
        "\n",
        "model_0 = breast_cancer_model_v1().to(device)\n",
        "model_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSPgfg3kEqhc",
        "outputId": "0a1f1846-3f2d-4487-fada-b601f62fb531"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "breast_cancer_model_v1(\n",
              "  (layer_1): Linear(in_features=30, out_features=100, bias=True)\n",
              "  (layer_2): Linear(in_features=100, out_features=50, bias=True)\n",
              "  (layer_3): Linear(in_features=50, out_features=25, bias=True)\n",
              "  (layer_4): Linear(in_features=25, out_features=10, bias=True)\n",
              "  (layer_5): Linear(in_features=10, out_features=5, bias=True)\n",
              "  (layer_6): Linear(in_features=5, out_features=3, bias=True)\n",
              "  (layer_7): Linear(in_features=3, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look at the model's state dict, I am sure it will be really complicated\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2Zft2QeHqf7",
        "outputId": "3e19d06f-c09f-4e5e-e179-ef905a1e790e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('layer_1.weight',\n",
              "              tensor([[ 0.1063,  0.0518,  0.1129,  ..., -0.0535,  0.0544, -0.0047],\n",
              "                      [-0.0431, -0.1539,  0.0232,  ...,  0.1399, -0.1647,  0.1050],\n",
              "                      [-0.0090, -0.1401,  0.1491,  ...,  0.1481,  0.1164,  0.1124],\n",
              "                      ...,\n",
              "                      [-0.1391, -0.1232,  0.0434,  ..., -0.0388, -0.0376, -0.0628],\n",
              "                      [-0.1452, -0.0092, -0.0748,  ..., -0.1194,  0.0989, -0.1145],\n",
              "                      [ 0.1118, -0.0517,  0.0936,  ...,  0.1538,  0.0808, -0.0990]],\n",
              "                     device='cuda:0')),\n",
              "             ('layer_1.bias',\n",
              "              tensor([-0.1133,  0.0985, -0.0759,  0.1673, -0.1200, -0.1628,  0.0152, -0.0818,\n",
              "                      -0.0587,  0.1638,  0.0542,  0.0360,  0.0944,  0.1480, -0.0210,  0.1700,\n",
              "                       0.1335,  0.0914,  0.0285,  0.0383,  0.0073, -0.0862, -0.0013, -0.0746,\n",
              "                      -0.0430,  0.0020, -0.0756, -0.0529,  0.1294,  0.0574,  0.0716, -0.1250,\n",
              "                      -0.0990,  0.0204, -0.0688,  0.1083,  0.0494, -0.0302, -0.0690,  0.1000,\n",
              "                      -0.1205, -0.0653, -0.1608,  0.0711, -0.0082, -0.0293, -0.0282,  0.1792,\n",
              "                       0.1422, -0.1210, -0.1281, -0.1307,  0.0133,  0.1162, -0.0674,  0.0380,\n",
              "                      -0.1500, -0.0572, -0.1438,  0.0864,  0.0551,  0.0254,  0.0232,  0.1352,\n",
              "                       0.0612,  0.1077, -0.1394, -0.1380, -0.0230,  0.0166, -0.1587,  0.0668,\n",
              "                       0.1349, -0.0758,  0.0909, -0.1393, -0.0174, -0.1290,  0.0163, -0.0358,\n",
              "                       0.1681,  0.0979,  0.0716,  0.1034,  0.0720, -0.1672, -0.1449, -0.0022,\n",
              "                      -0.0015,  0.0026,  0.0621,  0.0212, -0.1263,  0.1478, -0.1400,  0.0852,\n",
              "                      -0.0624,  0.0328,  0.0305,  0.1451], device='cuda:0')),\n",
              "             ('layer_2.weight',\n",
              "              tensor([[-0.0993, -0.0802, -0.0937,  ..., -0.0249,  0.0501,  0.0973],\n",
              "                      [ 0.0517, -0.0777, -0.0572,  ...,  0.0113, -0.0270,  0.0651],\n",
              "                      [-0.0308,  0.0997, -0.0533,  ..., -0.0237,  0.0006, -0.0444],\n",
              "                      ...,\n",
              "                      [-0.0156, -0.0084, -0.0772,  ...,  0.0547, -0.0880, -0.0869],\n",
              "                      [-0.0400, -0.0772, -0.0127,  ...,  0.0679,  0.0456,  0.0066],\n",
              "                      [-0.0359,  0.0591,  0.0674,  ..., -0.0015, -0.0881, -0.0144]],\n",
              "                     device='cuda:0')),\n",
              "             ('layer_2.bias',\n",
              "              tensor([-0.0554, -0.0840,  0.0154, -0.0956,  0.0902,  0.0845, -0.0640,  0.0095,\n",
              "                      -0.0771, -0.0727,  0.0877,  0.0886,  0.0060,  0.0691,  0.0876, -0.0378,\n",
              "                       0.0988,  0.0520,  0.0443,  0.0600, -0.0249, -0.0131, -0.0197, -0.0943,\n",
              "                      -0.0811, -0.0370, -0.0608,  0.0745,  0.0526,  0.0787,  0.0646,  0.0331,\n",
              "                       0.0717,  0.0196,  0.0369,  0.0960,  0.0557, -0.0045, -0.0178, -0.0241,\n",
              "                       0.0134, -0.0411, -0.0744, -0.0534, -0.0163, -0.0527, -0.0444, -0.0295,\n",
              "                       0.0614,  0.0618], device='cuda:0')),\n",
              "             ('layer_3.weight',\n",
              "              tensor([[ 0.0489,  0.1376,  0.0696,  ...,  0.0920,  0.1205,  0.0990],\n",
              "                      [ 0.0746, -0.1008, -0.0887,  ..., -0.0283,  0.0732, -0.0201],\n",
              "                      [-0.1024,  0.1190,  0.0559,  ...,  0.0122,  0.1027, -0.0526],\n",
              "                      ...,\n",
              "                      [ 0.0241,  0.0146, -0.1003,  ...,  0.0730, -0.1289,  0.0483],\n",
              "                      [ 0.0271, -0.0151, -0.0436,  ..., -0.1328, -0.1096, -0.0290],\n",
              "                      [-0.0133, -0.0467, -0.1138,  ...,  0.0388, -0.1126,  0.0262]],\n",
              "                     device='cuda:0')),\n",
              "             ('layer_3.bias',\n",
              "              tensor([ 0.0702,  0.1248, -0.0237, -0.0978, -0.0114, -0.1212, -0.0342, -0.0210,\n",
              "                      -0.0174,  0.0442,  0.0734, -0.0011, -0.1382, -0.0284, -0.1033, -0.0053,\n",
              "                      -0.0987, -0.1146, -0.0238,  0.0232, -0.1307,  0.0055, -0.0626, -0.0813,\n",
              "                      -0.0519], device='cuda:0')),\n",
              "             ('layer_4.weight',\n",
              "              tensor([[-0.1169,  0.1406,  0.1727,  0.1334,  0.0865,  0.0935,  0.1056,  0.1401,\n",
              "                        0.1999,  0.0950,  0.0094, -0.0248, -0.0065, -0.1795, -0.1741, -0.0416,\n",
              "                       -0.0403, -0.0507,  0.1776,  0.0144,  0.1217, -0.0719, -0.0048, -0.0603,\n",
              "                       -0.0306],\n",
              "                      [ 0.0004,  0.1138, -0.1529, -0.0613,  0.1923,  0.0303, -0.0091, -0.0966,\n",
              "                       -0.0354, -0.0484, -0.1222, -0.0946, -0.1680,  0.0202, -0.1204,  0.1793,\n",
              "                       -0.1476, -0.0018,  0.0587, -0.1456,  0.0679, -0.0967, -0.1860,  0.1136,\n",
              "                       -0.0362],\n",
              "                      [-0.0436,  0.0031,  0.1634, -0.1278,  0.0313,  0.0344, -0.1713,  0.0541,\n",
              "                        0.0014,  0.0030, -0.1287, -0.1535,  0.0281, -0.1747, -0.0188, -0.1703,\n",
              "                       -0.0751,  0.0040, -0.1022, -0.0684, -0.0812, -0.0595, -0.0651, -0.1499,\n",
              "                        0.1663],\n",
              "                      [-0.1091, -0.1203,  0.0087,  0.0979, -0.0278,  0.1862,  0.0101,  0.1607,\n",
              "                       -0.0788,  0.0059,  0.1071,  0.1011,  0.1325, -0.1883, -0.1191,  0.1853,\n",
              "                       -0.0275,  0.0705, -0.1545, -0.0258, -0.1437,  0.0387,  0.0792,  0.0891,\n",
              "                       -0.0008],\n",
              "                      [-0.0359,  0.1335, -0.0556,  0.1580,  0.1975,  0.1773,  0.1196, -0.0946,\n",
              "                       -0.0568, -0.0144,  0.0293, -0.0215, -0.1941,  0.0428, -0.1815,  0.0992,\n",
              "                       -0.1043, -0.0922,  0.1074,  0.1087, -0.1504, -0.1205, -0.0440, -0.1755,\n",
              "                       -0.0329],\n",
              "                      [ 0.0916, -0.0373, -0.0974, -0.0679, -0.0601,  0.0167, -0.0398, -0.1106,\n",
              "                        0.0629, -0.1995,  0.0518, -0.0576, -0.0424,  0.1471, -0.0387, -0.0359,\n",
              "                       -0.1625, -0.0858,  0.0010,  0.0932,  0.1826,  0.0856, -0.1521, -0.0207,\n",
              "                       -0.1175],\n",
              "                      [-0.1080, -0.0372,  0.1048,  0.1749, -0.1201, -0.1067, -0.1621,  0.1073,\n",
              "                        0.1191,  0.0121,  0.1563, -0.1371,  0.0255, -0.0559,  0.1465, -0.0846,\n",
              "                        0.0263,  0.1637,  0.1527,  0.1282,  0.1547, -0.0355,  0.1240,  0.1837,\n",
              "                       -0.1812],\n",
              "                      [-0.1676, -0.0818,  0.1270, -0.1139,  0.0197,  0.1047,  0.0527, -0.0067,\n",
              "                        0.1452, -0.0716, -0.1437,  0.1089,  0.0118, -0.1805, -0.1948,  0.1612,\n",
              "                       -0.1059, -0.1599, -0.1257,  0.1541,  0.0602,  0.0215, -0.1258, -0.1253,\n",
              "                       -0.1148],\n",
              "                      [ 0.0864, -0.0935, -0.0411,  0.0124,  0.1465, -0.1422,  0.1310,  0.1899,\n",
              "                        0.1631, -0.1718, -0.0367, -0.0084,  0.0120, -0.0454,  0.0453, -0.0771,\n",
              "                        0.0283, -0.0251, -0.0068,  0.1966, -0.0713, -0.1093, -0.0038,  0.0850,\n",
              "                        0.0088],\n",
              "                      [ 0.0213,  0.0160, -0.1771,  0.0881,  0.1854, -0.1647, -0.0767,  0.1733,\n",
              "                       -0.1718, -0.1994,  0.0239,  0.1560, -0.1945, -0.1059, -0.1709,  0.0710,\n",
              "                        0.1979,  0.1793,  0.1230, -0.1887, -0.1245,  0.0701, -0.0447,  0.0177,\n",
              "                       -0.1204]], device='cuda:0')),\n",
              "             ('layer_4.bias',\n",
              "              tensor([-0.0900,  0.0279,  0.0710, -0.0043, -0.1830,  0.1517,  0.0697,  0.1045,\n",
              "                      -0.1762, -0.0396], device='cuda:0')),\n",
              "             ('layer_5.weight',\n",
              "              tensor([[ 0.2464,  0.2566, -0.1832, -0.3014, -0.0862,  0.1751,  0.1878, -0.0722,\n",
              "                        0.1353, -0.2294],\n",
              "                      [-0.1464, -0.2330, -0.1112, -0.2808,  0.1602,  0.1924,  0.2879, -0.0456,\n",
              "                       -0.0979, -0.1765],\n",
              "                      [-0.1142, -0.1301, -0.0812,  0.2640,  0.1579, -0.2007,  0.2710,  0.1655,\n",
              "                        0.0480, -0.3008],\n",
              "                      [ 0.2807,  0.0721,  0.1747, -0.2976, -0.2847,  0.0481,  0.1646, -0.0538,\n",
              "                        0.1019, -0.2399],\n",
              "                      [-0.3159, -0.2698, -0.0134,  0.0026,  0.1158, -0.2035, -0.1357, -0.1545,\n",
              "                       -0.3024, -0.1499]], device='cuda:0')),\n",
              "             ('layer_5.bias',\n",
              "              tensor([ 0.0986, -0.2673, -0.0359, -0.2041, -0.0812], device='cuda:0')),\n",
              "             ('layer_6.weight',\n",
              "              tensor([[-0.1321,  0.4170,  0.2952,  0.3986, -0.3672],\n",
              "                      [ 0.2837,  0.3218,  0.3936, -0.1650,  0.2717],\n",
              "                      [ 0.3332,  0.4432,  0.3037,  0.2818,  0.2892]], device='cuda:0')),\n",
              "             ('layer_6.bias',\n",
              "              tensor([-0.0809,  0.3044, -0.0602], device='cuda:0')),\n",
              "             ('layer_7.weight',\n",
              "              tensor([[ 0.2419,  0.3903, -0.4004]], device='cuda:0')),\n",
              "             ('layer_7.bias', tensor([0.5000], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "okay since we have 7 layers, it creates a dictioanary of weights and biases of \"neurons\" in these 7 layers. This is pretty cool, actually!"
      ],
      "metadata": {
        "id": "RnBQYSY4IVhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make predictions with our untrained model (random weights and biases)\n",
        "untrained_preds = model_0(X_test.to(device))\n",
        "print(f\"Length of predictions: {len(untrained_preds)}, Shape: {untrained_preds.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qlwNRaFLSPY",
        "outputId": "98e8a1f7-2bbf-4a28-add4-7bcb606eba9d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of predictions: 114, Shape: torch.Size([114, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "untrained_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ga93vWVLtTq",
        "outputId": "52334e11-5fd3-49b4-bccd-16089197a0c5"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6233],\n",
              "        [0.6148],\n",
              "        [0.6074],\n",
              "        [0.6259],\n",
              "        [0.6104],\n",
              "        [0.6151],\n",
              "        [0.6371],\n",
              "        [0.6105],\n",
              "        [0.5981],\n",
              "        [0.6248]], device='cuda:0', grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jqrXviOMDwG",
        "outputId": "49fba4bd-018e-450e-de31-9c82bc0b4b1d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so our predictions are whacky right now and they were supposed to be like this. next we have to train our model and then make new predictions."
      ],
      "metadata": {
        "id": "HKl1GrrvMR7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Loss function and optimizer\n",
        "\n",
        "since we are working with binary class classification, we'll use\n",
        "`torch.nn.BCELossWithLogits` and for optimizer we might use SGD or Adam optimizer\n"
      ],
      "metadata": {
        "id": "wlkMW-ANMp4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup the loss function\n",
        "loss_fn = nn.BCEWithLogitsLoss() # sigmoid activation function built-in\n",
        "\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.001)"
      ],
      "metadata": {
        "id": "rZCsa-zfNixd"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate accuracy - out of 100 examples, what % does our model get right?\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct/len(y_pred)) * 100\n",
        "  return acc\n"
      ],
      "metadata": {
        "id": "3EUS93JmObCi"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Train model\n",
        "\n",
        "1. Forward pass\n",
        "2. Calculate the loss\n",
        "3. Optimizer the grad\n",
        "4. Loss backward (backpropagation)\n",
        "5. Optimizer step (gradient descent)"
      ],
      "metadata": {
        "id": "sKNbzc7DO1au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(37)\n",
        "torch.cuda.manual_seed(37)\n",
        "\n",
        "# set the number of epochs\n",
        "epochs = 100\n",
        "\n",
        "# put data to target device\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "# build training and evaluation loop\n",
        "for epoch in range(epochs):\n",
        "    ### Training\n",
        "    model_0.train()\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_logits = model_0(X_train).squeeze()\n",
        "    y_pred = torch.round(torch.sigmoid(y_logits))\n",
        "\n",
        "    # 2. Loss/accuracy\n",
        "    loss = loss_fn(y_logits, y_train)\n",
        "    acc = accuracy_fn(y_true=y_train, y_pred=y_pred)\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward (backpropagation)\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step (gradient descent)\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "        # 1. Forward pass\n",
        "        test_logits = model_0(X_test).squeeze()\n",
        "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
        "\n",
        "        # 2. Calculate test loss/acc\n",
        "        test_loss = loss_fn(test_logits, y_test)\n",
        "        test_acc = accuracy_fn(y_true=y_test, y_pred=test_pred)\n",
        "\n",
        "    # print out what's happening every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEThvyLdO8AF",
        "outputId": "65eb5495-e0a4-4456-e455-749378e2d155"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.81090, Acc: 37.80% | Test Loss: 0.82774, Test acc: 35.09%\n",
            "Epoch: 10 | Loss: 0.80963, Acc: 37.80% | Test Loss: 0.82635, Test acc: 35.09%\n",
            "Epoch: 20 | Loss: 0.80837, Acc: 37.80% | Test Loss: 0.82497, Test acc: 35.09%\n",
            "Epoch: 30 | Loss: 0.80713, Acc: 37.80% | Test Loss: 0.82361, Test acc: 35.09%\n",
            "Epoch: 40 | Loss: 0.80589, Acc: 37.80% | Test Loss: 0.82225, Test acc: 35.09%\n",
            "Epoch: 50 | Loss: 0.80466, Acc: 37.80% | Test Loss: 0.82091, Test acc: 35.09%\n",
            "Epoch: 60 | Loss: 0.80345, Acc: 37.80% | Test Loss: 0.81957, Test acc: 35.09%\n",
            "Epoch: 70 | Loss: 0.80224, Acc: 37.80% | Test Loss: 0.81824, Test acc: 35.09%\n",
            "Epoch: 80 | Loss: 0.80104, Acc: 37.80% | Test Loss: 0.81693, Test acc: 35.09%\n",
            "Epoch: 90 | Loss: 0.79985, Acc: 37.80% | Test Loss: 0.81562, Test acc: 35.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seems like our model isn't learning anything from the data, we'll see what's happening here later"
      ],
      "metadata": {
        "id": "LTHFBX1HeItZ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hApIZ0RkPr3K"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "29aQlO2WYb23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DoB4WJp8Yb06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I9AlTpoJYby9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B11DTeLXYbwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kghB8uAgYf72"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}